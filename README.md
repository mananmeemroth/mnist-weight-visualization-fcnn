# ðŸ”¥ MNIST Representation & Spatial Awareness Study  
**Repo:** mnist-fcnn-representation-study

## ðŸ“Œ Overview
This project studies how Fully Connected Neural Networks (FCNNs) learn image representations and whether they understand spatial structure.

Two experiments were conducted on MNIST:
1. Weight visualization of first hidden layer neurons  
2. Training on pixel-scrambled MNIST  

---

## ðŸ§ª Experiment 1 â€” Weight Visualization
- Trained FCNN on MNIST  
- Extracted first-layer neuron weights  
- Reshaped to 28Ã—28 and visualized as heatmaps  

**Observation:**  
Neurons capture global stroke/intensity patterns but lack localized spatial awareness.

---

## ðŸ§ª Experiment 2 â€” Scrambled MNIST
- Applied fixed random pixel permutation to all images  
- Trained same FCNN architecture  

**Result:**  
Accuracy remained nearly identical to normal MNIST.

**Insight:**  
FCNN treats images as flat vectors and lacks spatial inductive bias.

---

## ðŸ›  Tech Stack
- PyTorch / TensorFlow  
- NumPy  
- Matplotlib  

---

## ðŸŽ¯ Core Takeaway
High accuracy does not imply spatial understanding.  
FCNNs perform well on MNIST without learning true 2D structure â€” explaining why CNNs dominate vision tasks.
